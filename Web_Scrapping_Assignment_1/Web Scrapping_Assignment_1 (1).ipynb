{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf5ae2ab",
   "metadata": {},
   "source": [
    "# Write a python program to display all the header tags from wikipedia.org and make data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02bae8b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Header Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>h1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>h1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>h2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>h2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>h2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>h2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>h2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>h2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>h2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>h2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Header Tag\n",
       "0         h1\n",
       "1         h1\n",
       "2         h2\n",
       "3         h2\n",
       "4         h2\n",
       "5         h2\n",
       "6         h2\n",
       "7         h2\n",
       "8         h2\n",
       "9         h2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://en.wikipedia.org\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "header_tags = [h.name for h in soup.find_all([\"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\"])]\n",
    "df = pd.DataFrame(header_tags, columns=[\"Header Tag\"])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7bbbd9",
   "metadata": {},
   "source": [
    "# Write a python program to display IMDB’s Top rated 50 movies’ data (i.e. name, rating, year of release) and make data frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca0b3ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>IMDB Rating</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Godfather Part II</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Schindler's List</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Lord of the Rings: The Return of the King</td>\n",
       "      <td>8.9</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pulp Fiction</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Lord of the Rings: The Fellowship of the Ring</td>\n",
       "      <td>8.8</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Il buono, il brutto, il cattivo</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Forrest Gump</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Fight Club</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The Lord of the Rings: The Two Towers</td>\n",
       "      <td>8.7</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Inception</td>\n",
       "      <td>8.7</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The Empire Strikes Back</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The Matrix</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GoodFellas</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>One Flew Over the Cuckoo's Nest</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Se7en</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Shichinin no samurai</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>It's a Wonderful Life</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>The Silence of the Lambs</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Cidade de Deus</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Saving Private Ryan</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Interstellar</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>La vita è bella</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>The Green Mile</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Star Wars</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Terminator 2: Judgment Day</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Back to the Future</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Sen to Chihiro no kamikakushi</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>The Pianist</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Psycho</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Gisaengchung</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Léon</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>The Lion King</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Gladiator</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>American History X</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>The Departed</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>The Usual Suspects</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>The Prestige</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Whiplash</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Casablanca</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Seppuku</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Hotaru no haka</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>The Intouchables</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Modern Times</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Once Upon a Time in the West</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Rear Window</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Nuovo Cinema Paradiso</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title IMDB Rating  Year\n",
       "0                            The Shawshank Redemption         9.2  1994\n",
       "1                                       The Godfather         9.2  1972\n",
       "2                                     The Dark Knight         9.0  2008\n",
       "3                               The Godfather Part II         9.0  1974\n",
       "4                                        12 Angry Men         9.0  1957\n",
       "5                                    Schindler's List         8.9  1993\n",
       "6       The Lord of the Rings: The Return of the King         8.9  2003\n",
       "7                                        Pulp Fiction         8.8  1994\n",
       "8   The Lord of the Rings: The Fellowship of the Ring         8.8  2001\n",
       "9                     Il buono, il brutto, il cattivo         8.8  1966\n",
       "10                                       Forrest Gump         8.8  1994\n",
       "11                                         Fight Club         8.7  1999\n",
       "12              The Lord of the Rings: The Two Towers         8.7  2002\n",
       "13                                          Inception         8.7  2010\n",
       "14                            The Empire Strikes Back         8.7  1980\n",
       "15                                         The Matrix         8.7  1999\n",
       "16                                         GoodFellas         8.7  1990\n",
       "17                    One Flew Over the Cuckoo's Nest         8.6  1975\n",
       "18                                              Se7en         8.6  1995\n",
       "19                               Shichinin no samurai         8.6  1954\n",
       "20                              It's a Wonderful Life         8.6  1946\n",
       "21                           The Silence of the Lambs         8.6  1991\n",
       "22                                     Cidade de Deus         8.6  2002\n",
       "23                                Saving Private Ryan         8.6  1998\n",
       "24                                       Interstellar         8.6  2014\n",
       "25                                    La vita è bella         8.6  1997\n",
       "26                                     The Green Mile         8.6  1999\n",
       "27                                          Star Wars         8.5  1977\n",
       "28                         Terminator 2: Judgment Day         8.5  1991\n",
       "29                                 Back to the Future         8.5  1985\n",
       "30                      Sen to Chihiro no kamikakushi         8.5  2001\n",
       "31                                        The Pianist         8.5  2002\n",
       "32                                             Psycho         8.5  1960\n",
       "33                                       Gisaengchung         8.5  2019\n",
       "34                                               Léon         8.5  1994\n",
       "35                                      The Lion King         8.5  1994\n",
       "36                                          Gladiator         8.5  2000\n",
       "37                                 American History X         8.5  1998\n",
       "38                                       The Departed         8.5  2006\n",
       "39                                 The Usual Suspects         8.5  1995\n",
       "40                                       The Prestige         8.5  2006\n",
       "41                                           Whiplash         8.5  2014\n",
       "42                                         Casablanca         8.5  1942\n",
       "43                                            Seppuku         8.5  1962\n",
       "44                                     Hotaru no haka         8.5  1988\n",
       "45                                   The Intouchables         8.5  2011\n",
       "46                                       Modern Times         8.4  1936\n",
       "47                       Once Upon a Time in the West         8.4  1968\n",
       "48                                        Rear Window         8.4  1954\n",
       "49                              Nuovo Cinema Paradiso         8.4  1988"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.imdb.com/chart/top\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "movies = []\n",
    "rows = soup.find(\"tbody\", class_=\"lister-list\").find_all(\"tr\")[:50]\n",
    "for row in rows:\n",
    "    title = row.find(\"td\", class_=\"titleColumn\").find(\"a\").text\n",
    "    year = row.find(\"td\", class_=\"titleColumn\").find(\"span\").text[1:-1]\n",
    "    rating = row.find(\"td\", class_=\"ratingColumn\").find(\"strong\").text\n",
    "    movies.append([title, rating, year])\n",
    "\n",
    "df = pd.DataFrame(movies, columns=[\"Title\", \"IMDB Rating\", \"Year\"])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5574bbc5",
   "metadata": {},
   "source": [
    "# Write a python program in jupyter notebook without comments to display IMDB’s Top rated 50 Indian movies’ data (i.e. name, rating, year of release) and make data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22fadd2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>IMDB Rating</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ramayana: The Legend of Prince Rama</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rocketry: The Nambi Effect</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nayakan</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gol Maal</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anbe Sivam</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>777 Charlie</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jai Bhim</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pariyerum Perumal</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3 Idiots</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Apur Sansar</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Manichitrathazhu</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>#Home</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Soorarai Pottru</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Black Friday</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Kumbalangi Nights</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>C/o Kancharapalem</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Taare Zameen Par</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Kireedam</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Dangal</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Kaithi</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Jersey</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>96</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Maya Bazaar</td>\n",
       "      <td>8.2</td>\n",
       "      <td>1957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Natsamrat</td>\n",
       "      <td>8.2</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Asuran</td>\n",
       "      <td>8.2</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Drishyam 2</td>\n",
       "      <td>8.2</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Sita Ramam</td>\n",
       "      <td>8.2</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Thevar Magan</td>\n",
       "      <td>8.2</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Visaaranai</td>\n",
       "      <td>8.2</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Sarpatta Parambarai</td>\n",
       "      <td>8.2</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Thalapathi</td>\n",
       "      <td>8.2</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Pather Panchali</td>\n",
       "      <td>8.2</td>\n",
       "      <td>1955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Nadodikkattu</td>\n",
       "      <td>8.2</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Drishyam</td>\n",
       "      <td>8.2</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Jaane Bhi Do Yaaro</td>\n",
       "      <td>8.2</td>\n",
       "      <td>1983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Thani Oruvan</td>\n",
       "      <td>8.2</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Sardar Udham</td>\n",
       "      <td>8.2</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Aparajito</td>\n",
       "      <td>8.2</td>\n",
       "      <td>1956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Vada Chennai</td>\n",
       "      <td>8.2</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Khosla Ka Ghosla!</td>\n",
       "      <td>8.2</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Anniyan</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Ratsasan</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Chupke Chupke</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Gangs of Wasseypur</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Peranbu</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Drishyam</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Mahanati</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Bangalore Days</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Satya</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Agent Sai Srinivasa Athreya</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Title IMDB Rating  Year\n",
       "0   Ramayana: The Legend of Prince Rama         8.5  1993\n",
       "1            Rocketry: The Nambi Effect         8.4  2022\n",
       "2                               Nayakan         8.4  1987\n",
       "3                              Gol Maal         8.4  1979\n",
       "4                            Anbe Sivam         8.4  2003\n",
       "5                           777 Charlie         8.4  2022\n",
       "6                              Jai Bhim         8.4  2021\n",
       "7                     Pariyerum Perumal         8.4  2018\n",
       "8                              3 Idiots         8.4  2009\n",
       "9                           Apur Sansar         8.4  1959\n",
       "10                     Manichitrathazhu         8.4  1993\n",
       "11                                #Home         8.3  2021\n",
       "12                      Soorarai Pottru         8.3  2020\n",
       "13                         Black Friday         8.3  2004\n",
       "14                    Kumbalangi Nights         8.3  2019\n",
       "15                    C/o Kancharapalem         8.3  2018\n",
       "16                     Taare Zameen Par         8.3  2007\n",
       "17                             Kireedam         8.3  1989\n",
       "18                               Dangal         8.3  2016\n",
       "19                               Kaithi         8.3  2019\n",
       "20                               Jersey         8.3  2019\n",
       "21                                   96         8.3  2018\n",
       "22                          Maya Bazaar         8.2  1957\n",
       "23                            Natsamrat         8.2  2016\n",
       "24                               Asuran         8.2  2019\n",
       "25                           Drishyam 2         8.2  2021\n",
       "26                           Sita Ramam         8.2  2022\n",
       "27                         Thevar Magan         8.2  1992\n",
       "28                           Visaaranai         8.2  2015\n",
       "29                  Sarpatta Parambarai         8.2  2021\n",
       "30                           Thalapathi         8.2  1991\n",
       "31                      Pather Panchali         8.2  1955\n",
       "32                         Nadodikkattu         8.2  1987\n",
       "33                             Drishyam         8.2  2013\n",
       "34                   Jaane Bhi Do Yaaro         8.2  1983\n",
       "35                         Thani Oruvan         8.2  2015\n",
       "36                         Sardar Udham         8.2  2021\n",
       "37                            Aparajito         8.2  1956\n",
       "38                         Vada Chennai         8.2  2018\n",
       "39                    Khosla Ka Ghosla!         8.2  2006\n",
       "40                              Anniyan         8.1  2005\n",
       "41                             Ratsasan         8.1  2018\n",
       "42                        Chupke Chupke         8.1  1975\n",
       "43                   Gangs of Wasseypur         8.1  2012\n",
       "44                              Peranbu         8.1  2018\n",
       "45                             Drishyam         8.1  2015\n",
       "46                             Mahanati         8.1  2018\n",
       "47                       Bangalore Days         8.1  2014\n",
       "48                                Satya         8.1  1998\n",
       "49          Agent Sai Srinivasa Athreya         8.1  2019"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.imdb.com/india/top-rated-indian-movies/\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "movies = []\n",
    "rows = soup.find(\"tbody\", class_=\"lister-list\").find_all(\"tr\")[:50]\n",
    "for row in rows:\n",
    "    title = row.find(\"td\", class_=\"titleColumn\").find(\"a\").text\n",
    "    year = row.find(\"td\", class_=\"titleColumn\").find(\"span\").text[1:-1]\n",
    "    rating = row.find(\"td\", class_=\"ratingColumn\").find(\"strong\").text\n",
    "    movies.append([title, rating, year])\n",
    "\n",
    "df = pd.DataFrame(movies, columns=[\"Title\", \"IMDB Rating\", \"Year\"])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc11ed8",
   "metadata": {},
   "source": [
    "# Write a python program to display list of respected former presidents of India(i.e. Name , Term ofoffice) from https://presidentofindia.nic.in/former-presidents.htm and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "de0cfcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         President        Starting Date         Closing Date\n",
      "0           1. Dr. Rajendra Prasad   January 26th, 1950       May 13th, 1962\n",
      "1   2. Dr Sarvepalli Radhakrishnan       May 13th, 1962       May 13th, 1967\n",
      "2              3. Dr Zakir Hussain       May 13th, 1967        May 3rd, 1969\n",
      "3       4. Varahagiri Venkata Giri        May 3rd, 1969      July 20th, 1969\n",
      "4         5. Mohammad Hidayatullah      July 20th, 1969    August 24th, 1969\n",
      "5       6. Varahagiri Venkata Giri    August 24th, 1969    August 24th, 1974\n",
      "6          7. Fakhruddin Ali Ahmed    August 24th, 1974  February 11th, 1977\n",
      "7         8. Basappa Danappa Jatti  February 11th, 1977      July 25th, 1977\n",
      "8          9. Neelam Sanjiva Reddy      July 25th, 1977      July 25th, 1982\n",
      "9             10. Giani Zail Singh      July 25th, 1982      July 25th, 1987\n",
      "10      11. Ramaswamy Venkataraman      July 25th, 1987      July 25th, 1992\n",
      "11        12. Shankar Dayal Sharma      July 25th, 1992      July 25th, 1997\n",
      "12    13. Kocheril Raman Narayanan      July 25th, 1997      July 25th, 2002\n",
      "13      14. Dr. A.P.J. Abdul Kalam      July 25th, 2002      July 25th, 2007\n",
      "14              15. Pratibha Patil      July 25th, 2007      July 25th, 2012\n",
      "15            16. Pranab Mukherjee      July 25th, 2012      July 25th, 2017\n",
      "16        17. Shri Ram Nath Kovind      July 25th, 2017      July 21st, 2022\n",
      "17              18. Droupadi Murmu      July 21st, 2022              Working\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "page=requests.get('https://presidentofindia.nic.in/former-presidents.htm')\n",
    "soup = BeautifulSoup(page.content)\n",
    "soup\n",
    "\n",
    "pres=[]\n",
    "for i in soup.find_all('div', class_=\"presidentListing\"):\n",
    "    pres.append(i.text.split('(')[0])\n",
    "    pres.append(i.text.split('(')[1:2])\n",
    "   \n",
    "    \n",
    "pres\n",
    "\n",
    "df = pd.DataFrame(president_data, columns=['President', 'Starting Date', 'Closing Date'])\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad4d7dc",
   "metadata": {},
   "source": [
    "# Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20685bf3",
   "metadata": {},
   "source": [
    "# a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae1f5ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Team           Matches Points Rating\n",
      "0    1        India\\nIND     44  5,010\n",
      "1    2    Australia\\nAUS     32  3,572\n",
      "2    3   New Zealand\\nNZ     29  3,229\n",
      "3    4      England\\nENG     33  3,656\n",
      "4    5     Pakistan\\nPAK     25  2,649\n",
      "5    6  South Africa\\nSA     27  2,775\n",
      "6    7   Bangladesh\\nBAN     33  3,129\n",
      "7    8     Sri Lanka\\nSL     34  2,976\n",
      "8    9  Afghanistan\\nAFG     20  1,419\n",
      "9   10   West Indies\\nWI     41  2,902\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "rows = soup.find(\"table\").find_all(\"tr\")[1:11]\n",
    "\n",
    "data = []\n",
    "for row in rows:\n",
    "    cells = row.find_all(\"td\")\n",
    "    team = cells[0].text.strip()\n",
    "    matches = cells[1].text.strip()\n",
    "    points = cells[2].text.strip()\n",
    "    rating = cells[3].text.strip()\n",
    "    data.append([team, matches, points, rating])\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"Team\", \"Matches\", \"Points\", \"Rating\"])\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfed5f52",
   "metadata": {},
   "source": [
    "# b) Top 10 ODI Batsmen along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6c4a3281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Player Team Rating\n",
      "0  Rassie van der Dussen   SA    787\n",
      "1           David Warner  AUS    747\n",
      "2        Quinton de Kock   SA    743\n",
      "3            Imam-ul-Haq  PAK    740\n",
      "4           Shubman Gill  IND    734\n",
      "5            Virat Kohli  IND    727\n",
      "6            Steve Smith  AUS    719\n",
      "7           Rohit Sharma  IND    719\n",
      "8        Kane Williamson   NZ    700\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "rows = soup.find(\"table\").find_all(\"tr\")[1:11]\n",
    "\n",
    "data = []\n",
    "for row in rows:\n",
    "    cells = row.find_all(\"td\")\n",
    "    player = cells[1].text.strip()\n",
    "    team = cells[2].text.strip()\n",
    "    rating = cells[3].text.strip()\n",
    "    data.append([player, team, rating])\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"Player\", \"Team\", \"Rating\"])\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f89a9a0",
   "metadata": {},
   "source": [
    "# c) Top 10 ODI bowlers along with the records of their team and rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8f51370a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Player Team Rating\n",
      "0     Mohammed Siraj  IND    729\n",
      "1     Josh Hazlewood  AUS    727\n",
      "2        Trent Boult   NZ    708\n",
      "3     Mitchell Starc  AUS    665\n",
      "4        Rashid Khan  AFG    659\n",
      "5         Adam Zampa  AUS    655\n",
      "6    Shakib Al Hasan  BAN    652\n",
      "7     Shaheen Afridi  PAK    641\n",
      "8  Mustafizur Rahman  BAN    638\n",
      "9   Mujeeb Ur Rahman  AFG    637\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "rows = soup.find(\"table\").find_all(\"tr\")[1:11]\n",
    "\n",
    "data = []\n",
    "for row in rows:\n",
    "    cells = row.find_all(\"td\")\n",
    "    player = cells[1].text.strip()\n",
    "    team = cells[2].text.strip()\n",
    "    rating = cells[3].text.strip()\n",
    "    data.append([player, team, rating])\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"Player\", \"Team\", \"Rating\"])\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d608b95e",
   "metadata": {},
   "source": [
    "# Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab51fc5c",
   "metadata": {},
   "source": [
    "# a)Top 10 ODI teams in women’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e56d7197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Team           Matches Points Rating\n",
      "0    1    Australia\\nAUS     21  3,603\n",
      "1    2      England\\nENG     28  3,342\n",
      "2    3  South Africa\\nSA     26  3,098\n",
      "3    4        India\\nIND     27  2,820\n",
      "4    5   New Zealand\\nNZ     25  2,553\n",
      "5    6   West Indies\\nWI     27  2,535\n",
      "6    7   Bangladesh\\nBAN     13    983\n",
      "7    8     Thailand\\nTHA      8    572\n",
      "8    9     Pakistan\\nPAK     27  1,678\n",
      "9   10     Sri Lanka\\nSL      8    353\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "rows = soup.find(\"table\").find_all(\"tr\")[1:11]\n",
    "\n",
    "data = []\n",
    "for row in rows:\n",
    "    cells = row.find_all(\"td\")\n",
    "    team = cells[0].text.strip()\n",
    "    matches = cells[1].text.strip()\n",
    "    points = cells[2].text.strip()\n",
    "    rating = cells[3].text.strip()\n",
    "    data.append([team, matches, points, rating])\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"Team\", \"Matches\", \"Points\", \"Rating\"])\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce29bb3",
   "metadata": {},
   "source": [
    "# b) Top 10 women’s ODI Batting players along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4351ff23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Player Team Rating\n",
      "0         Alyssa Healy  AUS    762\n",
      "1          Beth Mooney  AUS    754\n",
      "2      Laura Wolvaardt   SA    732\n",
      "3       Natalie Sciver  ENG    731\n",
      "4          Meg Lanning  AUS    717\n",
      "5     Harmanpreet Kaur  IND    716\n",
      "6      Smriti Mandhana  IND    714\n",
      "7       Rachael Haynes  AUS    680\n",
      "8  Chamari Athapaththu   SL    655\n",
      "9    Amy Satterthwaite   NZ    641\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "rows = soup.find(\"table\").find_all(\"tr\")[1:11]\n",
    "\n",
    "data = []\n",
    "for row in rows:\n",
    "    cells = row.find_all(\"td\")\n",
    "    player = cells[1].text.strip()\n",
    "    team = cells[2].text.strip()\n",
    "    rating = cells[3].text.strip()\n",
    "    data.append([player, team, rating])\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"Player\", \"Team\", \"Rating\"])\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1599782a",
   "metadata": {},
   "source": [
    "# c) Top 10 women’s ODI all-rounder along with the records of their team and rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dbdecab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Player Team Rating\n",
      "0   Hayley Matthews   WI    373\n",
      "1    Natalie Sciver  ENG    371\n",
      "2      Ellyse Perry  AUS    366\n",
      "3    Marizanne Kapp   SA    349\n",
      "4       Amelia Kerr   NZ    336\n",
      "5     Deepti Sharma  IND    322\n",
      "6  Ashleigh Gardner  AUS    292\n",
      "7     Jess Jonassen  AUS    250\n",
      "8          Nida Dar  PAK    232\n",
      "9    Jhulan Goswami  IND    214\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "rows = soup.find(\"table\").find_all(\"tr\")[1:11]\n",
    "\n",
    "data = []\n",
    "for row in rows:\n",
    "    cells = row.find_all(\"td\")\n",
    "    player = cells[1].text.strip()\n",
    "    team = cells[2].text.strip()\n",
    "    rating = cells[3].text.strip()\n",
    "    data.append([player, team, rating])\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"Player\", \"Team\", \"Rating\"])\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4630a21d",
   "metadata": {},
   "source": [
    "# Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world and make data framei) Headline ii) Time iii) News Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff1cb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "page=requests.get('https://www.cnbc.com/world/?region=world')\n",
    "soup = BeautifulSoup(page.content)\n",
    "soup\n",
    "\n",
    "headline=soup.find('div', class_='FeaturedCard-content')\n",
    "headline.text\n",
    "\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({\"headline\":headline})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "528bfbd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"U.S. inflation report has the potential to deliver some bad newsYields are popping again. Here's how investors can take advantage CNBC Daily Open: U.S. markets rose, but might be surprised by January's consumer price index \""
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "258cf8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1=soup.find('div', class_class=\"ArticleHeader-time\")\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906a40c2",
   "metadata": {},
   "source": [
    "# Write a python program to scrape the details of most downloaded articles from AI in last 90 days.https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles Scrape below mentioned details and make data framei) Paper Title ii) Authors iii) Published Date iv) Paper URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ac426347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>Silver, David, Singh, Satinder, Precup, Doina,...</td>\n",
       "      <td>[October 2021]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Making sense of raw input</td>\n",
       "      <td>Evans, Richard, Bošnjak, Matko and 5 more</td>\n",
       "      <td>[October 2021]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Prakken, Henry, Sartor, Giovanni</td>\n",
       "      <td>[October 2015]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>Boden, Margaret A.</td>\n",
       "      <td>[August 1998]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>Lemaignan, Séverin, Warnier, Mathieu and 3 more</td>\n",
       "      <td>[June 2017]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "      <td>Miller, Tim February 2019</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Making sense of sensory input</td>\n",
       "      <td>Evans, Richard, Hernández-Orallo, José and 3 more</td>\n",
       "      <td>[April 2021]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "      <td>Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...</td>\n",
       "      <td>[February 2015]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "      <td>Sutton, Richard S., Precup, Doina, Singh, Sati...</td>\n",
       "      <td>[August 1999]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "      <td>Bard, Nolan, Foerster, Jakob N. and 13 more</td>\n",
       "      <td>[March 2020]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "      <td>van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...</td>\n",
       "      <td>[February 2021]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Argumentation in artificial intelligence</td>\n",
       "      <td>Bench-Capon, T.J.M., Dunne, Paul E.</td>\n",
       "      <td>[October 2007]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Algorithms for computing strategies in two-pla...</td>\n",
       "      <td>Bošanský, Branislav, Lisý, Viliam and 3 more</td>\n",
       "      <td>[August 2016]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "      <td>Luo, Wenhan, Xing, Junliang and 4 moreApril 2021</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Selection of relevant features and examples in...</td>\n",
       "      <td>Blum, Avrim L., Langley, Pat</td>\n",
       "      <td>[December 1997]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "      <td>Arora, Saurabh, Doshi, Prashant August 2021</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "      <td>Aas, Kjersti, Jullum, Martin, Løland, Anders</td>\n",
       "      <td>[September 2021]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "      <td>Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...</td>\n",
       "      <td>[June 2021]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Integrating social power into the decision-mak...</td>\n",
       "      <td>Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.</td>\n",
       "      <td>[December 2016]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>“That's (not) the output I expected!” On the r...</td>\n",
       "      <td>Riveiro, Maria, Thill, Serge</td>\n",
       "      <td>[September 2021]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "      <td>Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...</td>\n",
       "      <td>[May 2021]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Algorithm runtime prediction: Methods &amp; evalua...</td>\n",
       "      <td>Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...</td>\n",
       "      <td>[January 2014]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "      <td>Kohavi, Ron, John, George H.</td>\n",
       "      <td>[December 1997]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Commonsense visual sensemaking for autonomous ...</td>\n",
       "      <td>Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...</td>\n",
       "      <td>[October 2021]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Quantum computation, quantum theory and AI</td>\n",
       "      <td>Ying, Mingsheng</td>\n",
       "      <td>[February 2010]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0                                    Reward is enough   \n",
       "1                           Making sense of raw input   \n",
       "2   Law and logic: A review from an argumentation ...   \n",
       "3              Creativity and artificial intelligence   \n",
       "4   Artificial cognition for social human–robot in...   \n",
       "5   Explanation in artificial intelligence: Insigh...   \n",
       "6                       Making sense of sensory input   \n",
       "7   Conflict-based search for optimal multi-agent ...   \n",
       "8   Between MDPs and semi-MDPs: A framework for te...   \n",
       "9   The Hanabi challenge: A new frontier for AI re...   \n",
       "10  Evaluating XAI: A comparison of rule-based and...   \n",
       "11           Argumentation in artificial intelligence   \n",
       "12  Algorithms for computing strategies in two-pla...   \n",
       "13      Multiple object tracking: A literature review   \n",
       "14  Selection of relevant features and examples in...   \n",
       "15  A survey of inverse reinforcement learning: Ch...   \n",
       "16  Explaining individual predictions when feature...   \n",
       "17  A review of possible effects of cognitive bias...   \n",
       "18  Integrating social power into the decision-mak...   \n",
       "19  “That's (not) the output I expected!” On the r...   \n",
       "20  Explaining black-box classifiers using post-ho...   \n",
       "21  Algorithm runtime prediction: Methods & evalua...   \n",
       "22              Wrappers for feature subset selection   \n",
       "23  Commonsense visual sensemaking for autonomous ...   \n",
       "24         Quantum computation, quantum theory and AI   \n",
       "\n",
       "                                               author              date  \n",
       "0   Silver, David, Singh, Satinder, Precup, Doina,...    [October 2021]  \n",
       "1           Evans, Richard, Bošnjak, Matko and 5 more    [October 2021]  \n",
       "2                   Prakken, Henry, Sartor, Giovanni     [October 2015]  \n",
       "3                                 Boden, Margaret A.      [August 1998]  \n",
       "4     Lemaignan, Séverin, Warnier, Mathieu and 3 more       [June 2017]  \n",
       "5                           Miller, Tim February 2019                []  \n",
       "6   Evans, Richard, Hernández-Orallo, José and 3 more      [April 2021]  \n",
       "7   Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...   [February 2015]  \n",
       "8   Sutton, Richard S., Precup, Doina, Singh, Sati...     [August 1999]  \n",
       "9         Bard, Nolan, Foerster, Jakob N. and 13 more      [March 2020]  \n",
       "10  van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...   [February 2021]  \n",
       "11               Bench-Capon, T.J.M., Dunne, Paul E.     [October 2007]  \n",
       "12       Bošanský, Branislav, Lisý, Viliam and 3 more     [August 2016]  \n",
       "13   Luo, Wenhan, Xing, Junliang and 4 moreApril 2021                []  \n",
       "14                      Blum, Avrim L., Langley, Pat    [December 1997]  \n",
       "15        Arora, Saurabh, Doshi, Prashant August 2021                []  \n",
       "16      Aas, Kjersti, Jullum, Martin, Løland, Anders   [September 2021]  \n",
       "17  Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...       [June 2021]  \n",
       "18    Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.    [December 2016]  \n",
       "19                      Riveiro, Maria, Thill, Serge   [September 2021]  \n",
       "20  Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...        [May 2021]  \n",
       "21  Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...    [January 2014]  \n",
       "22                      Kohavi, Ron, John, George H.    [December 1997]  \n",
       "23  Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...    [October 2021]  \n",
       "24                                   Ying, Mingsheng    [February 2010]  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "page=requests.get('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')\n",
    "soup = BeautifulSoup(page.content)\n",
    "soup\n",
    "\n",
    "title=[]\n",
    "for i in soup.find_all('h2', class_='sc-1qrq3sd-1 gRGSUS sc-1nmom32-0 sc-1nmom32-1 btcbYu goSKRg'):\n",
    "    title.append(i.text)\n",
    "    \n",
    "title\n",
    "\n",
    "author=[]\n",
    "for i in soup.find_all('p', class_='sc-1thf9ly-0 sc-1thf9ly-1 iwnLUR fXmEge'):\n",
    "    author.append(i.text.split('Open')[0])\n",
    "    \n",
    "author\n",
    "\n",
    "date=[]\n",
    "for i in soup.find_all('p', class_='sc-1thf9ly-0 sc-1thf9ly-1 iwnLUR fXmEge'):\n",
    "    date.append(i.text.split('Access')[1:2])\n",
    "    \n",
    "date\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.DataFrame({'title':title, 'author':author, 'date':date})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba85ca5",
   "metadata": {},
   "source": [
    "# Write a python program to scrape mentioned details from dineout.co.in and make data framei) Restaurant name ii) Cuisine iii) Location iv) Ratings v) Image URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "85dfe100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Castle Barbeque',\n",
       " 'Jungle Jamboree',\n",
       " 'Cafe Knosh',\n",
       " 'Castle Barbeque',\n",
       " 'The Barbeque Company',\n",
       " 'India Grill',\n",
       " 'Delhi Barbeque',\n",
       " 'The Monarch - Bar Be Que Village',\n",
       " 'Indian Grill Room']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "page=requests.get('https://www.dineout.co.in/delhi-restaurants/buffet-special')\n",
    "soup = BeautifulSoup(page.content)\n",
    "soup\n",
    "\n",
    "res=[]\n",
    "for i in soup.find_all('a', class_='restnt-name ellipsis'):\n",
    "    res.append(i.text)\n",
    "res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "391fcfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc=[]\n",
    "for i in soup.find_all('div', class_='restnt-loc ellipsis'):\n",
    "    loc.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "aaff5274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Connaught Place, Central Delhi',\n",
       " '3CS Mall,Lajpat Nagar - 3, South Delhi',\n",
       " 'The Leela Ambience Convention Hotel,Shahdara, East Delhi',\n",
       " 'Pacific Mall,Tagore Garden, West Delhi',\n",
       " 'Gardens Galleria,Sector 38A, Noida',\n",
       " 'Hilton Garden Inn,Saket, South Delhi',\n",
       " 'Taurus Sarovar Portico,Mahipalpur, South Delhi',\n",
       " 'Indirapuram Habitat Centre,Indirapuram, Ghaziabad',\n",
       " 'Suncity Business Tower,Golf Course Road, Gurgaon']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7f776b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Chinese, North Indian',\n",
       " ' North Indian, Asian, Italian',\n",
       " ' Italian, Continental',\n",
       " ' Chinese, North Indian',\n",
       " ' North Indian, Chinese',\n",
       " ' North Indian, Italian',\n",
       " ' North Indian',\n",
       " ' North Indian',\n",
       " ' North Indian, Mughlai']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cus=[]\n",
    "for i in soup.find_all('div', class_=\"detail-info\"):\n",
    "    cus.append(i.text.split('|')[1])\n",
    "cus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8d775b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4.1', '3.9', '4.3', '3.9', '4', '3.9', '3.6', '3.8', '4.3']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating=[]\n",
    "for i in soup.find_all('div', class_='restnt-rating rating-4'):\n",
    "    rating.append(i.text)\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e6718355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://im1.dineout.co.in/images/uploads/restaurant/sharpen/8/k/b/p86792-16062953735fbe1f4d3fb7e.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/5/p/m/p59633-166088382462ff137009010.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/4/p/m/p406-15438184745c04ccea491bc.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/3/j/o/p38113-15959192065f1fcb666130c.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/7/p/k/p79307-16051787755fad1597f2bf9.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/2/v/t/p2687-1482477169585cce712b90f.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/5/d/i/p52501-1661855212630de5eceb6d2.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/3/n/o/p34822-15599107305cfa594a13c24.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/5/y/f/p549-165000147262590640c0afc.jpg?tr=tr:n-medium']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image=[]\n",
    "for i in soup.find_all('img', class_=\"no-img\"):\n",
    "    image.append(i.get('data-src'))\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8071a86d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant</th>\n",
       "      <th>Location</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jungle Jamboree</td>\n",
       "      <td>3CS Mall,Lajpat Nagar - 3, South Delhi</td>\n",
       "      <td>North Indian, Asian, Italian</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cafe Knosh</td>\n",
       "      <td>The Leela Ambience Convention Hotel,Shahdara, ...</td>\n",
       "      <td>Italian, Continental</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>Pacific Mall,Tagore Garden, West Delhi</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Barbeque Company</td>\n",
       "      <td>Gardens Galleria,Sector 38A, Noida</td>\n",
       "      <td>North Indian, Chinese</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>India Grill</td>\n",
       "      <td>Hilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>North Indian, Italian</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Delhi Barbeque</td>\n",
       "      <td>Taurus Sarovar Portico,Mahipalpur, South Delhi</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>3.6</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Monarch - Bar Be Que Village</td>\n",
       "      <td>Indirapuram Habitat Centre,Indirapuram, Ghaziabad</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>3.8</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Indian Grill Room</td>\n",
       "      <td>Suncity Business Tower,Golf Course Road, Gurgaon</td>\n",
       "      <td>North Indian, Mughlai</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Restaurant  \\\n",
       "0                   Castle Barbeque   \n",
       "1                   Jungle Jamboree   \n",
       "2                        Cafe Knosh   \n",
       "3                   Castle Barbeque   \n",
       "4              The Barbeque Company   \n",
       "5                       India Grill   \n",
       "6                    Delhi Barbeque   \n",
       "7  The Monarch - Bar Be Que Village   \n",
       "8                 Indian Grill Room   \n",
       "\n",
       "                                            Location  \\\n",
       "0                     Connaught Place, Central Delhi   \n",
       "1             3CS Mall,Lajpat Nagar - 3, South Delhi   \n",
       "2  The Leela Ambience Convention Hotel,Shahdara, ...   \n",
       "3             Pacific Mall,Tagore Garden, West Delhi   \n",
       "4                 Gardens Galleria,Sector 38A, Noida   \n",
       "5               Hilton Garden Inn,Saket, South Delhi   \n",
       "6     Taurus Sarovar Portico,Mahipalpur, South Delhi   \n",
       "7  Indirapuram Habitat Centre,Indirapuram, Ghaziabad   \n",
       "8   Suncity Business Tower,Golf Course Road, Gurgaon   \n",
       "\n",
       "                         Cuisine Rating  \\\n",
       "0          Chinese, North Indian    4.1   \n",
       "1   North Indian, Asian, Italian    3.9   \n",
       "2           Italian, Continental    4.3   \n",
       "3          Chinese, North Indian    3.9   \n",
       "4          North Indian, Chinese      4   \n",
       "5          North Indian, Italian    3.9   \n",
       "6                   North Indian    3.6   \n",
       "7                   North Indian    3.8   \n",
       "8          North Indian, Mughlai    4.3   \n",
       "\n",
       "                                               Image  \n",
       "0  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({\"Restaurant\":res, \"Location\": loc, \"Cuisine\":cus, \"Rating\":rating, \"Image\":image})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d4fa9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
